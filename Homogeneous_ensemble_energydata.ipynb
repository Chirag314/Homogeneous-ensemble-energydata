{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMcNXLiYUDP+APh/Uw0wYFk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chirag314/Homogeneous-ensemble-energydata/blob/main/Homogeneous_ensemble_energydata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###This notebook is made from exercises from book Ensemble Machine Learning Cookbook."
      ],
      "metadata": {
        "id": "de3ggC8Kv_99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the case of ensemble models, each base classifier must have some degree of diversity within itself. This diversity can be obtained in one of the following manners:\n",
        "\n",
        "By using different subsets of training data through various resampling methods or randomization of the training data\n",
        "By using different learning hyperparameters for different base learners\n",
        "By using different learning algorithms \n",
        "In the case of ensemble models, where different algorithms are used for the base learners, the ensemble is called a heterogeneous ensemble method. If the same algorithm is used for all the base learners on different distributions of the training set, the ensemble is called a homogeneous ensemble. "
      ],
      "metadata": {
        "id": "jIDLriSFoPIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "CWjW7ISB-O8s"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rror9ooAv2jU",
        "outputId": "b7d9e27f-d2d9-40b5-ea78-cc7b8af82285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            date  Appliances  lights     T1       RH_1    T2       RH_2  \\\n",
            "0  1/11/16 17:00          60      30  19.89  47.596667  19.2  44.790000   \n",
            "1  1/11/16 17:10          60      30  19.89  46.693333  19.2  44.722500   \n",
            "2  1/11/16 17:20          50      30  19.89  46.300000  19.2  44.626667   \n",
            "3  1/11/16 17:30          50      40  19.89  46.066667  19.2  44.590000   \n",
            "4  1/11/16 17:40          60      40  19.89  46.333333  19.2  44.530000   \n",
            "\n",
            "      T3       RH_3         T4       RH_4         T5   RH_5        T6  \\\n",
            "0  19.79  44.730000  19.000000  45.566667  17.166667  55.20  7.026667   \n",
            "1  19.79  44.790000  19.000000  45.992500  17.166667  55.20  6.833333   \n",
            "2  19.79  44.933333  18.926667  45.890000  17.166667  55.09  6.560000   \n",
            "3  19.79  45.000000  18.890000  45.723333  17.166667  55.09  6.433333   \n",
            "4  19.79  45.000000  18.890000  45.530000  17.200000  55.09  6.366667   \n",
            "\n",
            "        RH_6         T7       RH_7    T8       RH_8         T9   RH_9  T_out  \\\n",
            "0  84.256667  17.200000  41.626667  18.2  48.900000  17.033333  45.53   6.60   \n",
            "1  84.063333  17.200000  41.560000  18.2  48.863333  17.066667  45.56   6.48   \n",
            "2  83.156667  17.200000  41.433333  18.2  48.730000  17.000000  45.50   6.37   \n",
            "3  83.423333  17.133333  41.290000  18.1  48.590000  17.000000  45.40   6.25   \n",
            "4  84.893333  17.200000  41.230000  18.1  48.590000  17.000000  45.40   6.13   \n",
            "\n",
            "   Press_mm_hg  RH_out  Windspeed  Visibility  Tdewpoint        rv1        rv2  \n",
            "0        733.5    92.0   7.000000   63.000000        5.3  13.275433  13.275433  \n",
            "1        733.6    92.0   6.666667   59.166667        5.2  18.606195  18.606195  \n",
            "2        733.7    92.0   6.333333   55.333333        5.1  28.642668  28.642668  \n",
            "3        733.8    92.0   6.000000   51.500000        5.0  45.410390  45.410390  \n",
            "4        733.9    92.0   5.666667   47.666667        4.9  10.084097  10.084097  \n"
          ]
        }
      ],
      "source": [
        "# Read data from github. Use raw format and copy url# Note normal url and raw url will be different.\n",
        "import pandas as pd\n",
        "pd.options.display.max_rows=None\n",
        "pd.options.display.max_columns=None\n",
        "url = 'https://raw.githubusercontent.com/PacktPublishing/Ensemble-Machine-Learning-Cookbook/master/Chapter09/energydata.csv'\n",
        "df_energydata= pd.read_csv(url)\n",
        "#df = pd.read_csv(url)\n",
        "print(df_energydata.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check missing values\n",
        "df_energydata.isnull().sum()\n",
        "#It seems there are no missing data in any featues\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x7pcl0DQA3B",
        "outputId": "fd92b894-04e4-4abf-8e00-904731a119dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date           0\n",
              "Appliances     0\n",
              "lights         0\n",
              "T1             0\n",
              "RH_1           0\n",
              "T2             0\n",
              "RH_2           0\n",
              "T3             0\n",
              "RH_3           0\n",
              "T4             0\n",
              "RH_4           0\n",
              "T5             0\n",
              "RH_5           0\n",
              "T6             0\n",
              "RH_6           0\n",
              "T7             0\n",
              "RH_7           0\n",
              "T8             0\n",
              "RH_8           0\n",
              "T9             0\n",
              "RH_9           0\n",
              "T_out          0\n",
              "Press_mm_hg    0\n",
              "RH_out         0\n",
              "Windspeed      0\n",
              "Visibility     0\n",
              "Tdewpoint      0\n",
              "rv1            0\n",
              "rv2            0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate the test subset to apply the models in order to make predictions\n",
        "df_traindata,df_testdata=train_test_split(df_energydata,test_size=0.3)"
      ],
      "metadata": {
        "id": "8jf4wreqQNCQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the shape of the train and test subsets:\n",
        "print(df_traindata.shape)\n",
        "print(df_testdata.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0__PvA3Qapy",
        "outputId": "881e849a-6f94-45c9-c422-a0ca6b68a332"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13814, 29)\n",
            "(5921, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Take the test subset and split it into target and feature variables\n",
        "X_test=df_testdata.iloc[:,3:27]\n",
        "Y_test=df_testdata.iloc[:,28]"
      ],
      "metadata": {
        "id": "07gDJxFnQm3Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Validate the preceding split by checking the shape of X_test and Y_test\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uHjY15CQvWs",
        "outputId": "1c66c787-993d-4982-b774-13997491c6d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5921, 24)\n",
            "(5921,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's create multiple neural network models using Keras. We use For...Loop to build multiple models\n",
        "ensemble=20\n",
        "frac=0.7\n",
        "\n",
        "predictions_total=np.zeros(5921,dtype=float)\n",
        "\n",
        "for i in range(ensemble):\n",
        "  print(\"number of iteration :\",i)\n",
        "  print(\"prediction_total\",predictions_total)\n",
        "\n",
        "  #Sample randomly the train data\n",
        "  Traindata=df_traindata.sample(frac=frac)\n",
        "  X_train=Traindata.iloc[:,3:27]\n",
        "  Y_train=Traindata.iloc[:,28]\n",
        "\n",
        "  model=Sequential()\n",
        "   # Adding the input layer and the first hidden layer\n",
        "  model.add(Dense(units=16,kernel_initializer='normal',activation='relu'))\n",
        "  model.add(Dense(units=24,kernel_initializer='normal',activation='relu'))\n",
        "  model.add(Dense(units = 32, kernel_initializer = 'normal', activation = 'relu'))\n",
        "  model.add(Dense(units = 1, kernel_initializer = 'normal', activation = 'relu'))\n",
        "\n",
        "  #compiling the ANN\n",
        "  adam=keras.optimizers.Adam(lr=0.001,beta_1=0.9,beta_2=0.9,epsilon=None,decay=0.0)\n",
        "  model.compile(loss='mse',optimizer=adam,metrics=['mean_squared_error'])\n",
        "\n",
        "  #Fitting on training set\n",
        "  model.fit(X_train, Y_train,batch_size=16,epochs=25)\n",
        "\n",
        "  #Predict the values\n",
        "  model_predictions=model.predict(X_test)\n",
        "  model_predictions=model_predictions.flatten()\n",
        "  print(\"Test MSE for individual model: \",mean_squared_error(Y_test,model_predictions))\n",
        "  print(\"\")\n",
        "  print(model_predictions)\n",
        "  print(\"\")\n",
        "\n",
        "predictions_total=np.add(predictions_total, model_predictions)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFXkr9MLQ7py",
        "outputId": "cf0b9908-bcba-4983-8a2b-579f4b029696"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of iteration : 0\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 832.2219 - mean_squared_error: 832.2219\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2220 - mean_squared_error: 832.2220\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2224 - mean_squared_error: 832.2224\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2217 - mean_squared_error: 832.2217\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2216 - mean_squared_error: 832.2216\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2220 - mean_squared_error: 832.2220\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2214 - mean_squared_error: 832.2214\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2213 - mean_squared_error: 832.2213\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2217 - mean_squared_error: 832.2217\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2217 - mean_squared_error: 832.2217\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2217 - mean_squared_error: 832.2217\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2220 - mean_squared_error: 832.2220\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2219 - mean_squared_error: 832.2219\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2217 - mean_squared_error: 832.2217\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2217 - mean_squared_error: 832.2217\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2215 - mean_squared_error: 832.2215\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2214 - mean_squared_error: 832.2214\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2220 - mean_squared_error: 832.2220\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2216 - mean_squared_error: 832.2216\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2217 - mean_squared_error: 832.2217\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2219 - mean_squared_error: 832.2219\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2221 - mean_squared_error: 832.2221\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2222 - mean_squared_error: 832.2222\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2214 - mean_squared_error: 832.2214\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.2216 - mean_squared_error: 832.2216\n",
            "Test MSE for individual model:  836.9763385502636\n",
            "\n",
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "\n",
            "number of iteration : 1\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 838.2268 - mean_squared_error: 838.2268\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2274 - mean_squared_error: 838.2274\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2265 - mean_squared_error: 838.2265\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2266 - mean_squared_error: 838.2266\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2267 - mean_squared_error: 838.2267\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2270 - mean_squared_error: 838.2270\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2275 - mean_squared_error: 838.2275\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2273 - mean_squared_error: 838.2273\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2272 - mean_squared_error: 838.2272\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2261 - mean_squared_error: 838.2261\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2270 - mean_squared_error: 838.2270\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2272 - mean_squared_error: 838.2272\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2267 - mean_squared_error: 838.2267\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2265 - mean_squared_error: 838.2265\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2269 - mean_squared_error: 838.2269\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2274 - mean_squared_error: 838.2274\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2271 - mean_squared_error: 838.2271\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2268 - mean_squared_error: 838.2268\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2270 - mean_squared_error: 838.2270\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2268 - mean_squared_error: 838.2268\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 2s 3ms/step - loss: 838.2268 - mean_squared_error: 838.2268\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 3s 4ms/step - loss: 838.2267 - mean_squared_error: 838.2267\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2269 - mean_squared_error: 838.2269\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2267 - mean_squared_error: 838.2267\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 838.2268 - mean_squared_error: 838.2268\n",
            "Test MSE for individual model:  836.9763385502636\n",
            "\n",
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "\n",
            "number of iteration : 2\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 3s 3ms/step - loss: 826.4948 - mean_squared_error: 826.4948\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 826.4950 - mean_squared_error: 826.4950\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 826.4949 - mean_squared_error: 826.4949\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 826.4952 - mean_squared_error: 826.4952\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 826.4951 - mean_squared_error: 826.4951\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 2s 3ms/step - loss: 826.4953 - mean_squared_error: 826.4953\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 2s 3ms/step - loss: 826.4953 - mean_squared_error: 826.4953\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 3s 4ms/step - loss: 826.4950 - mean_squared_error: 826.4950\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 2s 4ms/step - loss: 826.4955 - mean_squared_error: 826.4955\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 2s 3ms/step - loss: 826.4953 - mean_squared_error: 826.4953\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 2s 3ms/step - loss: 826.4951 - mean_squared_error: 826.4951\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 826.4949 - mean_squared_error: 826.4949\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 826.4949 - mean_squared_error: 826.4949\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 826.4948 - mean_squared_error: 826.4948\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 826.4954 - mean_squared_error: 826.4954\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 826.4948 - mean_squared_error: 826.4948\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 826.4949 - mean_squared_error: 826.4949\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 2s 4ms/step - loss: 826.4951 - mean_squared_error: 826.4951\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 2s 3ms/step - loss: 826.4947 - mean_squared_error: 826.4947\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 2s 3ms/step - loss: 826.4952 - mean_squared_error: 826.4952\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 826.4952 - mean_squared_error: 826.4952\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 826.4954 - mean_squared_error: 826.4954\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 2s 3ms/step - loss: 826.4950 - mean_squared_error: 826.4950\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 826.4951 - mean_squared_error: 826.4951\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 826.4951 - mean_squared_error: 826.4951\n",
            "Test MSE for individual model:  836.9763385502636\n",
            "\n",
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "\n",
            "number of iteration : 3\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 247.5900 - mean_squared_error: 247.5900\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.4072 - mean_squared_error: 213.4072\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.3398 - mean_squared_error: 212.3398\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.6161 - mean_squared_error: 212.6161\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.0699 - mean_squared_error: 213.0699\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.5173 - mean_squared_error: 212.5173\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.5358 - mean_squared_error: 212.5358\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.4355 - mean_squared_error: 212.4355\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.1747 - mean_squared_error: 213.1747\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.4245 - mean_squared_error: 212.4245\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.9923 - mean_squared_error: 212.9923\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.1732 - mean_squared_error: 212.1732\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.1783 - mean_squared_error: 213.1783\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.8601 - mean_squared_error: 211.8601\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.6487 - mean_squared_error: 212.6487\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.8376 - mean_squared_error: 211.8376\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.6224 - mean_squared_error: 212.6224\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.2087 - mean_squared_error: 212.2087\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.8015 - mean_squared_error: 211.8015\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.4533 - mean_squared_error: 212.4533\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.1873 - mean_squared_error: 212.1873\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.0416 - mean_squared_error: 213.0416\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.5412 - mean_squared_error: 212.5412\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.0310 - mean_squared_error: 212.0310\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.9740 - mean_squared_error: 211.9740\n",
            "Test MSE for individual model:  210.00485779829677\n",
            "\n",
            "[23.83239  24.170807 23.71089  ... 24.047583 24.180254 24.092232]\n",
            "\n",
            "number of iteration : 4\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 245.3793 - mean_squared_error: 245.3793\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.9290 - mean_squared_error: 213.9290\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.7620 - mean_squared_error: 214.7620\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.5790 - mean_squared_error: 213.5790\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.7863 - mean_squared_error: 213.7863\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.7343 - mean_squared_error: 213.7343\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.4413 - mean_squared_error: 213.4413\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.1367 - mean_squared_error: 213.1367\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.8106 - mean_squared_error: 212.8106\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.6404 - mean_squared_error: 212.6404\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.6987 - mean_squared_error: 212.6987\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.5808 - mean_squared_error: 213.5808\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.1900 - mean_squared_error: 213.1900\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.2321 - mean_squared_error: 213.2321\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.6194 - mean_squared_error: 212.6194\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.6721 - mean_squared_error: 213.6721\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.1287 - mean_squared_error: 213.1287\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.6096 - mean_squared_error: 212.6096\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.0492 - mean_squared_error: 213.0492\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.8114 - mean_squared_error: 212.8114\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.9001 - mean_squared_error: 213.9001\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.0187 - mean_squared_error: 213.0187\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.3025 - mean_squared_error: 212.3025\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.7729 - mean_squared_error: 212.7729\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.1114 - mean_squared_error: 213.1114\n",
            "Test MSE for individual model:  211.2335782426322\n",
            "\n",
            "[23.654163 23.485935 23.49876  ... 23.626942 23.440626 23.639618]\n",
            "\n",
            "number of iteration : 5\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 245.9935 - mean_squared_error: 245.9935\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.9392 - mean_squared_error: 214.9392\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 215.2577 - mean_squared_error: 215.2577\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.9007 - mean_squared_error: 214.9007\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 215.3511 - mean_squared_error: 215.3511\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.3954 - mean_squared_error: 214.3954\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.2940 - mean_squared_error: 214.2940\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 215.3493 - mean_squared_error: 215.3493\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 215.3355 - mean_squared_error: 215.3355\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.1241 - mean_squared_error: 214.1241\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.2980 - mean_squared_error: 214.2980\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.3037 - mean_squared_error: 214.3037\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.5135 - mean_squared_error: 214.5135\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 215.1819 - mean_squared_error: 215.1819\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.6130 - mean_squared_error: 214.6130\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.9766 - mean_squared_error: 213.9766\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.0520 - mean_squared_error: 214.0520\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.2179 - mean_squared_error: 214.2179\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.1823 - mean_squared_error: 214.1823\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.2391 - mean_squared_error: 214.2391\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 215.5593 - mean_squared_error: 215.5593\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.9589 - mean_squared_error: 213.9589\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.4136 - mean_squared_error: 214.4136\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.9783 - mean_squared_error: 213.9783\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.6844 - mean_squared_error: 214.6844\n",
            "Test MSE for individual model:  208.84021474114022\n",
            "\n",
            "[25.417936 25.679611 25.497574 ... 25.647476 25.44191  25.378365]\n",
            "\n",
            "number of iteration : 6\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 245.9006 - mean_squared_error: 245.9006\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.3134 - mean_squared_error: 213.3134\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.2177 - mean_squared_error: 213.2177\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.4468 - mean_squared_error: 213.4468\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.1510 - mean_squared_error: 213.1510\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.8197 - mean_squared_error: 212.8197\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.5160 - mean_squared_error: 213.5160\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.1883 - mean_squared_error: 212.1883\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.4077 - mean_squared_error: 213.4077\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.9100 - mean_squared_error: 213.9100\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.8127 - mean_squared_error: 212.8127\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 2s 3ms/step - loss: 212.7771 - mean_squared_error: 212.7771\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.0094 - mean_squared_error: 212.0094\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.3296 - mean_squared_error: 212.3296\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.2707 - mean_squared_error: 213.2707\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.1883 - mean_squared_error: 212.1883\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.5410 - mean_squared_error: 212.5410\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.8669 - mean_squared_error: 212.8669\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.0763 - mean_squared_error: 212.0763\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.4142 - mean_squared_error: 212.4142\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.9301 - mean_squared_error: 212.9301\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.4972 - mean_squared_error: 212.4972\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.9392 - mean_squared_error: 211.9392\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.2041 - mean_squared_error: 213.2041\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.2322 - mean_squared_error: 212.2322\n",
            "Test MSE for individual model:  209.36668146028376\n",
            "\n",
            "[25.706144 25.73814  26.192846 ... 26.216892 25.856136 26.030573]\n",
            "\n",
            "number of iteration : 7\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 833.4974 - mean_squared_error: 833.4974\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4978 - mean_squared_error: 833.4978\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4974 - mean_squared_error: 833.4974\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4973 - mean_squared_error: 833.4973\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4977 - mean_squared_error: 833.4977\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4978 - mean_squared_error: 833.4978\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4976 - mean_squared_error: 833.4976\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4974 - mean_squared_error: 833.4974\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4974 - mean_squared_error: 833.4974\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4975 - mean_squared_error: 833.4975\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4977 - mean_squared_error: 833.4977\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4974 - mean_squared_error: 833.4974\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4977 - mean_squared_error: 833.4977\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4975 - mean_squared_error: 833.4975\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4973 - mean_squared_error: 833.4973\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4979 - mean_squared_error: 833.4979\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4974 - mean_squared_error: 833.4974\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4978 - mean_squared_error: 833.4978\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4976 - mean_squared_error: 833.4976\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4973 - mean_squared_error: 833.4973\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4977 - mean_squared_error: 833.4977\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4969 - mean_squared_error: 833.4969\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4976 - mean_squared_error: 833.4976\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4980 - mean_squared_error: 833.4980\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.4972 - mean_squared_error: 833.4972\n",
            "Test MSE for individual model:  836.9763385502636\n",
            "\n",
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "\n",
            "number of iteration : 8\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 244.5716 - mean_squared_error: 244.5716\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.3364 - mean_squared_error: 212.3364\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.4463 - mean_squared_error: 212.4463\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.0312 - mean_squared_error: 213.0312\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.3285 - mean_squared_error: 213.3285\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.3513 - mean_squared_error: 212.3513\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.9358 - mean_squared_error: 211.9358\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.6478 - mean_squared_error: 212.6478\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.6341 - mean_squared_error: 212.6341\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.4400 - mean_squared_error: 212.4400\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.3024 - mean_squared_error: 212.3024\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.9206 - mean_squared_error: 211.9206\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.8064 - mean_squared_error: 211.8064\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.8889 - mean_squared_error: 211.8889\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.7557 - mean_squared_error: 212.7557\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.1275 - mean_squared_error: 212.1275\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.8388 - mean_squared_error: 211.8388\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.9343 - mean_squared_error: 211.9343\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.0984 - mean_squared_error: 211.0984\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.5698 - mean_squared_error: 212.5698\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.5665 - mean_squared_error: 211.5665\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.5675 - mean_squared_error: 211.5675\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.8122 - mean_squared_error: 211.8122\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.5488 - mean_squared_error: 211.5488\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.7127 - mean_squared_error: 211.7127\n",
            "Test MSE for individual model:  209.25468996138807\n",
            "\n",
            "[24.320217 24.686432 24.503359 ... 24.562792 24.396818 24.261383]\n",
            "\n",
            "number of iteration : 9\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 245.8063 - mean_squared_error: 245.8063\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.9935 - mean_squared_error: 214.9935\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.9826 - mean_squared_error: 213.9826\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.6412 - mean_squared_error: 213.6412\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.5760 - mean_squared_error: 213.5760\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.2690 - mean_squared_error: 214.2690\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.2551 - mean_squared_error: 213.2551\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.3382 - mean_squared_error: 213.3382\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.3506 - mean_squared_error: 213.3506\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.2044 - mean_squared_error: 213.2044\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.7185 - mean_squared_error: 212.7185\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.0972 - mean_squared_error: 213.0972\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.0300 - mean_squared_error: 213.0300\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.1094 - mean_squared_error: 213.1094\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.0107 - mean_squared_error: 213.0107\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.2867 - mean_squared_error: 213.2867\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.9298 - mean_squared_error: 212.9298\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.1306 - mean_squared_error: 213.1306\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.3078 - mean_squared_error: 213.3078\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.8241 - mean_squared_error: 212.8241\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.3018 - mean_squared_error: 212.3018\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.0543 - mean_squared_error: 213.0543\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.9307 - mean_squared_error: 212.9307\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.7863 - mean_squared_error: 212.7863\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.7592 - mean_squared_error: 212.7592\n",
            "Test MSE for individual model:  209.64991902706765\n",
            "\n",
            "[26.021946 25.856943 26.214796 ... 26.224009 25.751293 25.771387]\n",
            "\n",
            "number of iteration : 10\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 236.8397 - mean_squared_error: 236.8397\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.3293 - mean_squared_error: 212.3293\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.0992 - mean_squared_error: 212.0992\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.9623 - mean_squared_error: 211.9623\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.3104 - mean_squared_error: 211.3104\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.0928 - mean_squared_error: 212.0928\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.2842 - mean_squared_error: 212.2842\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.1537 - mean_squared_error: 211.1537\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.0360 - mean_squared_error: 212.0360\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.5722 - mean_squared_error: 211.5722\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.7680 - mean_squared_error: 211.7680\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.2814 - mean_squared_error: 212.2814\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.6144 - mean_squared_error: 211.6144\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 210.9129 - mean_squared_error: 210.9129\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 210.7204 - mean_squared_error: 210.7204\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.5988 - mean_squared_error: 211.5988\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.3303 - mean_squared_error: 211.3303\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.0234 - mean_squared_error: 211.0234\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.5772 - mean_squared_error: 211.5772\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 210.7809 - mean_squared_error: 210.7809\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 210.5943 - mean_squared_error: 210.5943\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.5796 - mean_squared_error: 211.5796\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.1203 - mean_squared_error: 211.1203\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.3250 - mean_squared_error: 211.3250\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 210.9897 - mean_squared_error: 210.9897\n",
            "Test MSE for individual model:  209.21116846670228\n",
            "\n",
            "[24.542082 24.612036 24.47388  ... 24.592241 24.411184 24.330912]\n",
            "\n",
            "number of iteration : 11\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 840.0527 - mean_squared_error: 840.0527\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0531 - mean_squared_error: 840.0531\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0529 - mean_squared_error: 840.0529\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0533 - mean_squared_error: 840.0533\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0532 - mean_squared_error: 840.0532\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0533 - mean_squared_error: 840.0533\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0533 - mean_squared_error: 840.0533\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0532 - mean_squared_error: 840.0532\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0530 - mean_squared_error: 840.0530\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0528 - mean_squared_error: 840.0528\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0533 - mean_squared_error: 840.0533\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0530 - mean_squared_error: 840.0530\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0528 - mean_squared_error: 840.0528\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0536 - mean_squared_error: 840.0536\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0532 - mean_squared_error: 840.0532\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0532 - mean_squared_error: 840.0532\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0529 - mean_squared_error: 840.0529\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0535 - mean_squared_error: 840.0535\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0529 - mean_squared_error: 840.0529\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0538 - mean_squared_error: 840.0538\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0531 - mean_squared_error: 840.0531\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0532 - mean_squared_error: 840.0532\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0529 - mean_squared_error: 840.0529\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0532 - mean_squared_error: 840.0532\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 840.0530 - mean_squared_error: 840.0530\n",
            "Test MSE for individual model:  836.9763385502636\n",
            "\n",
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "\n",
            "number of iteration : 12\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 3s 3ms/step - loss: 241.3385 - mean_squared_error: 241.3385\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.0276 - mean_squared_error: 214.0276\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.2329 - mean_squared_error: 213.2329\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.1059 - mean_squared_error: 213.1059\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.2776 - mean_squared_error: 214.2776\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.3862 - mean_squared_error: 213.3862\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.7358 - mean_squared_error: 213.7358\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.0180 - mean_squared_error: 214.0180\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.5299 - mean_squared_error: 213.5299\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.9914 - mean_squared_error: 213.9914\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.1327 - mean_squared_error: 213.1327\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.4771 - mean_squared_error: 213.4771\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.7138 - mean_squared_error: 213.7138\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.7625 - mean_squared_error: 212.7625\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.2529 - mean_squared_error: 213.2529\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.2964 - mean_squared_error: 213.2964\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.8556 - mean_squared_error: 212.8556\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.0053 - mean_squared_error: 213.0053\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.8671 - mean_squared_error: 212.8671\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.7183 - mean_squared_error: 212.7183\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.5388 - mean_squared_error: 213.5388\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.6599 - mean_squared_error: 212.6599\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.9024 - mean_squared_error: 212.9024\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.8890 - mean_squared_error: 212.8890\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.6420 - mean_squared_error: 212.6420\n",
            "Test MSE for individual model:  210.88323991781047\n",
            "\n",
            "[23.67442  23.888689 23.565075 ... 23.726633 23.691141 23.500113]\n",
            "\n",
            "number of iteration : 13\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 836.8040 - mean_squared_error: 836.8040\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8033 - mean_squared_error: 836.8033\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8039 - mean_squared_error: 836.8039\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8038 - mean_squared_error: 836.8038\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8038 - mean_squared_error: 836.8038\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8035 - mean_squared_error: 836.8035\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8037 - mean_squared_error: 836.8037\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8040 - mean_squared_error: 836.8040\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8038 - mean_squared_error: 836.8038\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8036 - mean_squared_error: 836.8036\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8035 - mean_squared_error: 836.8035\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8034 - mean_squared_error: 836.8034\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8033 - mean_squared_error: 836.8033\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8041 - mean_squared_error: 836.8041\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8038 - mean_squared_error: 836.8038\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8037 - mean_squared_error: 836.8037\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8042 - mean_squared_error: 836.8042\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8038 - mean_squared_error: 836.8038\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8033 - mean_squared_error: 836.8033\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8036 - mean_squared_error: 836.8036\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8038 - mean_squared_error: 836.8038\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8041 - mean_squared_error: 836.8041\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8033 - mean_squared_error: 836.8033\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8041 - mean_squared_error: 836.8041\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 836.8037 - mean_squared_error: 836.8037\n",
            "Test MSE for individual model:  836.9763385502636\n",
            "\n",
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "\n",
            "number of iteration : 14\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 832.9061 - mean_squared_error: 832.9061\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9062 - mean_squared_error: 832.9062\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9060 - mean_squared_error: 832.9060\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9059 - mean_squared_error: 832.9059\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9062 - mean_squared_error: 832.9062\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9062 - mean_squared_error: 832.9062\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9069 - mean_squared_error: 832.9069\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9061 - mean_squared_error: 832.9061\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9057 - mean_squared_error: 832.9057\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9064 - mean_squared_error: 832.9064\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9062 - mean_squared_error: 832.9062\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9061 - mean_squared_error: 832.9061\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9064 - mean_squared_error: 832.9064\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9063 - mean_squared_error: 832.9063\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9068 - mean_squared_error: 832.9068\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9066 - mean_squared_error: 832.9066\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9064 - mean_squared_error: 832.9064\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9064 - mean_squared_error: 832.9064\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9062 - mean_squared_error: 832.9062\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9061 - mean_squared_error: 832.9061\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9059 - mean_squared_error: 832.9059\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9068 - mean_squared_error: 832.9068\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9064 - mean_squared_error: 832.9064\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9064 - mean_squared_error: 832.9064\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 832.9063 - mean_squared_error: 832.9063\n",
            "Test MSE for individual model:  836.9763385502636\n",
            "\n",
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "\n",
            "number of iteration : 15\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 827.8875 - mean_squared_error: 827.8875\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8872 - mean_squared_error: 827.8872\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8876 - mean_squared_error: 827.8876\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8875 - mean_squared_error: 827.8875\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8873 - mean_squared_error: 827.8873\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8879 - mean_squared_error: 827.8879\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8875 - mean_squared_error: 827.8875\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8874 - mean_squared_error: 827.8874\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8876 - mean_squared_error: 827.8876\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8873 - mean_squared_error: 827.8873\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8876 - mean_squared_error: 827.8876\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8875 - mean_squared_error: 827.8875\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8873 - mean_squared_error: 827.8873\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8875 - mean_squared_error: 827.8875\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8873 - mean_squared_error: 827.8873\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8881 - mean_squared_error: 827.8881\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8873 - mean_squared_error: 827.8873\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8877 - mean_squared_error: 827.8877\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8880 - mean_squared_error: 827.8880\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8877 - mean_squared_error: 827.8877\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8877 - mean_squared_error: 827.8877\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8875 - mean_squared_error: 827.8875\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8875 - mean_squared_error: 827.8875\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8878 - mean_squared_error: 827.8878\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 827.8874 - mean_squared_error: 827.8874\n",
            "Test MSE for individual model:  836.9763385502636\n",
            "\n",
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "\n",
            "number of iteration : 16\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 241.3600 - mean_squared_error: 241.3600\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.7128 - mean_squared_error: 213.7128\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.6543 - mean_squared_error: 213.6543\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.6857 - mean_squared_error: 213.6857\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.1737 - mean_squared_error: 213.1737\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 214.3754 - mean_squared_error: 214.3754\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.4290 - mean_squared_error: 213.4290\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.1429 - mean_squared_error: 213.1429\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.0493 - mean_squared_error: 213.0493\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.5695 - mean_squared_error: 212.5695\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.1415 - mean_squared_error: 213.1415\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.1212 - mean_squared_error: 213.1212\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.1565 - mean_squared_error: 213.1565\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.8332 - mean_squared_error: 212.8332\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.5627 - mean_squared_error: 212.5627\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.5532 - mean_squared_error: 212.5532\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.7774 - mean_squared_error: 212.7774\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.5232 - mean_squared_error: 212.5232\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.8444 - mean_squared_error: 212.8444\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.7966 - mean_squared_error: 212.7966\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.0435 - mean_squared_error: 213.0435\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 213.6522 - mean_squared_error: 213.6522\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.4393 - mean_squared_error: 212.4393\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.7602 - mean_squared_error: 212.7602\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.9657 - mean_squared_error: 212.9657\n",
            "Test MSE for individual model:  211.71499590665863\n",
            "\n",
            "[23.502918 23.46439  23.219273 ... 23.543373 23.41851  23.26132 ]\n",
            "\n",
            "number of iteration : 17\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 257.6036 - mean_squared_error: 257.6036\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.8952 - mean_squared_error: 212.8952\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.7821 - mean_squared_error: 212.7821\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.6515 - mean_squared_error: 212.6515\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.7125 - mean_squared_error: 212.7125\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.4240 - mean_squared_error: 212.4240\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.2092 - mean_squared_error: 212.2092\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.9650 - mean_squared_error: 211.9650\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.8961 - mean_squared_error: 211.8961\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.3504 - mean_squared_error: 212.3504\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.0726 - mean_squared_error: 212.0726\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.9526 - mean_squared_error: 211.9526\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.5399 - mean_squared_error: 212.5399\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.6219 - mean_squared_error: 211.6219\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.7184 - mean_squared_error: 211.7184\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.4904 - mean_squared_error: 212.4904\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.6004 - mean_squared_error: 211.6004\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.7368 - mean_squared_error: 211.7368\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.9006 - mean_squared_error: 211.9006\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.4229 - mean_squared_error: 212.4229\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.4593 - mean_squared_error: 212.4593\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 212.1813 - mean_squared_error: 212.1813\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.9711 - mean_squared_error: 211.9711\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 2s 3ms/step - loss: 212.5298 - mean_squared_error: 212.5298\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 211.7932 - mean_squared_error: 211.7932\n",
            "Test MSE for individual model:  209.4452103789244\n",
            "\n",
            "[24.489233 24.446594 24.04379  ... 24.390451 24.279915 24.040594]\n",
            "\n",
            "number of iteration : 18\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 830.7407 - mean_squared_error: 830.7407\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7413 - mean_squared_error: 830.7413\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7410 - mean_squared_error: 830.7410\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7411 - mean_squared_error: 830.7411\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7412 - mean_squared_error: 830.7412\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7410 - mean_squared_error: 830.7410\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7410 - mean_squared_error: 830.7410\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7410 - mean_squared_error: 830.7410\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7409 - mean_squared_error: 830.7409\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7411 - mean_squared_error: 830.7411\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7410 - mean_squared_error: 830.7410\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7410 - mean_squared_error: 830.7410\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7408 - mean_squared_error: 830.7408\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7408 - mean_squared_error: 830.7408\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7407 - mean_squared_error: 830.7407\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7407 - mean_squared_error: 830.7407\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7410 - mean_squared_error: 830.7410\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7407 - mean_squared_error: 830.7407\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7408 - mean_squared_error: 830.7408\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7414 - mean_squared_error: 830.7414\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7410 - mean_squared_error: 830.7410\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7417 - mean_squared_error: 830.7417\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7412 - mean_squared_error: 830.7412\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7411 - mean_squared_error: 830.7411\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 830.7405 - mean_squared_error: 830.7405\n",
            "Test MSE for individual model:  836.9763385502636\n",
            "\n",
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "\n",
            "number of iteration : 19\n",
            "prediction_total [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "605/605 [==============================] - 2s 2ms/step - loss: 833.1898 - mean_squared_error: 833.1898\n",
            "Epoch 2/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1894 - mean_squared_error: 833.1894\n",
            "Epoch 3/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1892 - mean_squared_error: 833.1892\n",
            "Epoch 4/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1899 - mean_squared_error: 833.1899\n",
            "Epoch 5/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1893 - mean_squared_error: 833.1893\n",
            "Epoch 6/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1893 - mean_squared_error: 833.1893\n",
            "Epoch 7/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1895 - mean_squared_error: 833.1895\n",
            "Epoch 8/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1896 - mean_squared_error: 833.1896\n",
            "Epoch 9/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1895 - mean_squared_error: 833.1895\n",
            "Epoch 10/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1894 - mean_squared_error: 833.1894\n",
            "Epoch 11/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1898 - mean_squared_error: 833.1898\n",
            "Epoch 12/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1895 - mean_squared_error: 833.1895\n",
            "Epoch 13/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1893 - mean_squared_error: 833.1893\n",
            "Epoch 14/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1896 - mean_squared_error: 833.1896\n",
            "Epoch 15/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1897 - mean_squared_error: 833.1897\n",
            "Epoch 16/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1898 - mean_squared_error: 833.1898\n",
            "Epoch 17/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1896 - mean_squared_error: 833.1896\n",
            "Epoch 18/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1899 - mean_squared_error: 833.1899\n",
            "Epoch 19/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1896 - mean_squared_error: 833.1896\n",
            "Epoch 20/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1896 - mean_squared_error: 833.1896\n",
            "Epoch 21/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1892 - mean_squared_error: 833.1892\n",
            "Epoch 22/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1895 - mean_squared_error: 833.1895\n",
            "Epoch 23/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1894 - mean_squared_error: 833.1894\n",
            "Epoch 24/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1898 - mean_squared_error: 833.1898\n",
            "Epoch 25/25\n",
            "605/605 [==============================] - 1s 2ms/step - loss: 833.1895 - mean_squared_error: 833.1895\n",
            "Test MSE for individual model:  836.9763385502636\n",
            "\n",
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Take the summation of the predicted values and divide them by the number of iterations to get the average predicted values. We use the average predicted values to calculate the mean-squared error (MSE) for our ensemble\n",
        "predictions_total=predictions_total/ensemble\n",
        "print(\"MSE after ensemble:\",mean_squared_error(np.array(Y_test),predictions_total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QO5X6uNS4Wb",
        "outputId": "cc245770-3387-4961-9958-de575a6e6893"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE after ensemble: 836.9763385502636\n"
          ]
        }
      ]
    }
  ]
}